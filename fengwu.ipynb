{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "444f406d-f8f3-4874-9216-0c2b5656a543",
   "metadata": {},
   "source": [
    "works with kernel Python \\[conda env:pangu] as constructed in README\n",
    "\n",
    "run fengwu with 1 GPU and 20 GB memory (must be v100, not gp100 because gp100 only has 16 GB VRAM, but v100 has 32GB)\n",
    "\n",
    "Make these the default casper modules `module save`\n",
    "\n",
    "```\n",
    "Currently Loaded Modules:\n",
    "  1) ncarenv/24.12  (S)   3) ncarcompilers/1.0.0   5) ucx/1.17.0      7) hdf5/1.12.3    9) cudnn/9.2.0.82-12\n",
    "  2) intel/2024.2.1       4) cuda/12.3.2           6) openmpi/5.0.6   8) netcdf/4.9.2  10) conda/latest\n",
    "```\n",
    "\n",
    "Inferences in conda env:ainwp is different by 0.0001 K from pangu env (after 240 hours)\n",
    "conda env:ainwp is supposed to replicate realtime runs, but still 0.1 K different from realtime runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504416c1-14db-4819-8b0b-8ece1eda2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray\n",
    "from run_pangu import plot_ensemble\n",
    "from run_pangu.s3_run_fengwu_ecmwf import (\n",
    "    ai_input_grb,\n",
    "    channel_subset,\n",
    "    fengwu_channels,\n",
    "    lat,\n",
    "    lon,\n",
    "    pressure_levels,\n",
    "    setup_model_sessions,\n",
    "    variables,\n",
    ")\n",
    "\n",
    "ai_models_dir = Path(\"/glade/derecho/scratch/ahijevyc/ai-models\")\n",
    "date = pd.to_datetime(\"2024042500\", format=\"%Y%m%d%H\")\n",
    "date_6 = date - pd.to_timedelta(\"6h\")\n",
    "ic = \"gefs\"\n",
    "fhr_end = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f593bb8e-0c50-4dcc-a67d-31a94eba80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ai_input_nc(nc):\n",
    "    input = xarray.open_dataset(nc)\n",
    "    sfc_param = [\"u10m\", \"v10m\", \"t2m\", \"msl\"]\n",
    "    pl_param = [f\"{f}{p}\" for f in variables for p in pressure_levels]\n",
    "    fields_all = []\n",
    "    for p in sfc_param + pl_param:\n",
    "        field = input[\"__xarray_dataarray_variable__\"].sel(channel=p).squeeze().values\n",
    "        fields_all.append(field)\n",
    "    return np.stack(fields_all)\n",
    "\n",
    "\n",
    "def run_fengwu(input, data_mean, data_std, date, ic, fhr_end, odir, clobber=False):\n",
    "    for fhr in range(6, fhr_end+1, 6):\n",
    "        output_filename = f\"{odir}/fengwu_{ic}_pred_{fhr:03d}.nc\"\n",
    "        if os.path.exists(output_filename):\n",
    "            if clobber:\n",
    "                os.remove(output_filename)\n",
    "            else:\n",
    "                continue\n",
    "        print(f\"Processing {date:%Y-%m-%d} - {fhr} hour\")\n",
    "        # \n",
    "        output = ort_session_6.run(None, {\"input\": input})[0]\n",
    "        input = np.concatenate((input[:, 69:], output[:, :69]), axis=1)\n",
    "        output = (output[0, :69] * data_std) + data_mean\n",
    "\n",
    "        # Create prediction timedelta\n",
    "        pred_timedelta = pd.Timedelta(hours=fhr)\n",
    "\n",
    "        # Create xarray DataArrays with proper dimensions\n",
    "        da_output = xarray.DataArray(\n",
    "            data=np.expand_dims(np.expand_dims(output, axis=0), axis=0),\n",
    "            coords={\n",
    "                \"init_time\": [date],\n",
    "                \"prediction_timedelta\": [pred_timedelta],\n",
    "                \"channel\": fengwu_channels,\n",
    "                \"lat\": lat,\n",
    "                \"lon\": lon,\n",
    "            },\n",
    "            dims=[\"init_time\", \"prediction_timedelta\", \"channel\", \"lat\", \"lon\"],\n",
    "        ).sel(lat=slice(60, 20), lon=slice(220, 300), channel=channel_subset)\n",
    "\n",
    "        # Save as netCDF\n",
    "        da_output.to_netcdf(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8554b-5848-4584-8789-96e365e25590",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(\"/glade/derecho/scratch/zxhua/AI_global_forecast_model_for_education/FengWu/model\")\n",
    "ort_session_6 = setup_model_sessions(model_dir)\n",
    "# Load normalization data\n",
    "data_mean = np.load(model_dir / \"data_mean.npy\")[:, np.newaxis, np.newaxis]\n",
    "data_std = np.load(model_dir / \"data_std.npy\")[:, np.newaxis, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f81b5-5cf2-47e5-b0b1-fd7f2391f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mem in [\"c00\"] + [f\"p{m:02d}\" for m in range(1, 31)]:  # gefs has 30 perturbed members; ecmwf has 50\n",
    "    ens = int(mem[1:])  # int() removes leading zeros\n",
    "    assert mem.startswith(\"p\") or mem == \"c00\"\n",
    "    odir = ai_models_dir / f\"output/fengwu/{date:%Y%m%d%H}/{mem}_att2\"\n",
    "    if all([Path(f\"{odir}/fengwu_{ic}_pred_{fhr:03d}.nc\").exists() for fhr in range(6,fhr_end+1,6)]):\n",
    "        print('.', end='')\n",
    "        continue\n",
    "\n",
    "    if ic == \"ecmwf\":\n",
    "        assert date > pd.to_datetime(\"20250209\"), \"started saving ecmwf after 20250209\"\n",
    "        prior_nc = f\"/glade/derecho/scratch/sobash/fengwu_realtime/{date:%Y%m%d%H}/ens{ens}/pangu_ens{ens}_init_{date_6:%Y%m%d%H}.nc\"\n",
    "        current_nc = f\"/glade/derecho/scratch/sobash/fengwu_realtime/{date:%Y%m%d%H}/ens{ens}/pangu_ens{ens}_init_{date:%Y%m%d%H}.nc\"\n",
    "        input_prior = fengwu_input_nc(prior_nc)\n",
    "        input_current = fengwu_input_nc(current_nc)\n",
    "    elif ic == \"gefs\":\n",
    "        from run_pangu import s1_get_gefs, s2_make_ic_gefs\n",
    "\n",
    "        assert ens <= 30\n",
    "        s1_get_gefs.download_time(date_6)\n",
    "        s1_get_gefs.download_time(date)\n",
    "\n",
    "        s2_make_ic_gefs.process_member(date_6.strftime(\"%Y%m%d%H\"), mem)\n",
    "        s2_make_ic_gefs.process_member(date.strftime(\"%Y%m%d%H\"), mem)\n",
    "        prior_grb = (\n",
    "            ai_models_dir / f\"input/{date_6:%Y%m%d%H}/{mem}/ge{mem}.t{date_6:%H}z.pgrb.0p25.f000\"\n",
    "        )\n",
    "        current_grb = (\n",
    "            ai_models_dir / f\"input/{date:%Y%m%d%H}/{mem}/ge{mem}.t{date:%H}z.pgrb.0p25.f000\"\n",
    "        )\n",
    "        input_prior = ai_input_grb(prior_grb)\n",
    "        input_current = ai_input_grb(current_grb)\n",
    "        # TODO: maybe run with ai-models-fengwu, an ai-models plugin\n",
    "        if False:\n",
    "            odir = current_grb.parent / \"input_data\"\n",
    "            os.makedirs(odir, exist_ok=True)\n",
    "            np.save(odir / \"input1.npy\", input_prior)\n",
    "            np.save(odir / \"input2.npy\", input_current)\n",
    "\n",
    "    # Normalize input data\n",
    "    input_current_after_norm = (input_current - data_mean) / data_std\n",
    "    input_prior_after_norm = (input_prior - data_mean) / data_std\n",
    "    input_fengwu = np.concatenate((input_prior_after_norm, input_current_after_norm), axis=0)[\n",
    "        np.newaxis, :, :, :\n",
    "    ]\n",
    "    input_fengwu = input_fengwu.astype(np.float32)\n",
    "\n",
    "    os.makedirs(odir, exist_ok=True)\n",
    "    run_fengwu(input_fengwu, data_mean, data_std, date, ic, fhr_end, odir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b93e5-69f7-49e3-8dbe-c58710e221aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace\n",
    "args.ic = ic.upper()\n",
    "args.model = \"fengwu\"\n",
    "ifiles = sorted(list((ai_models_dir / f\"output/fengwu/{date:%Y%m%d%H}\").glob(f\"[cp][0-9][0-9]/fengwu_{ic}_*\")))\n",
    "\n",
    "ai_models_dir / f\"output/fengwu/{date:%Y%m%d%H}/{mem}\"\n",
    "def daymultiple(f):\n",
    "    # multiple of 1 day\n",
    "    fhr = f.name[-6:-3]  # fhr part\n",
    "    return int(fhr) % 24 == 0\n",
    "\n",
    "\n",
    "ifiles = [f for f in ifiles if daymultiple(f)]\n",
    "print(len(ifiles))\n",
    "da = (\n",
    "    xarray.open_mfdataset(ifiles, decode_timedelta=True, preprocess=plot_ensemble.parsemem)\n",
    "    .sel(channel=\"z500\", init_time=date)\n",
    "    .squeeze()\n",
    "    .rename(__xarray_dataarray_variable__=\"z\")\n",
    "    .rename(lat=\"latitude\", lon=\"longitude\", prediction_timedelta=\"step\")\n",
    ")\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45989246-f08b-442f-a8a8-5be152e30843",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_ensemble.plot_forecast_grid(args, da, plotdays=[1, 2, 3, 4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143e36e-3d96-4986-a43c-3bf5ae99b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb95269-d3a3-4fd6-b31d-fbac7b4b250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = (\n",
    "    xarray.open_mfdataset((ai_models_dir / f\"output/fengwu/{date:%Y%m%d%H}/c00\").glob(\"*_ecmwf_*\"), decode_timedelta=True)\n",
    "    .sel(channel=\"t2m\", init_time=date)\n",
    "    .squeeze()[\"__xarray_dataarray_variable__\"]\n",
    "    .isel(prediction_timedelta=slice(None, None, 4))\n",
    ")\n",
    "da.sel(lat=slice(60, 20), lon=slice(220, 300)).plot(col=\"prediction_timedelta\", col_wrap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1cbff-114b-47b9-a57d-ea022f00db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_old = (\n",
    "    xarray.open_mfdataset(\n",
    "        Path(\n",
    "            f\"/glade/derecho/scratch/sobash/fengwu_realtime/{date:%Y%m%d%H}/ens{ens}/fengwu_forecast_data\"\n",
    "        ).glob(\"fengwu*.nc\"),\n",
    "        decode_timedelta=True,\n",
    "    )\n",
    "    .sel(channel=\"t2m\")\n",
    "    .squeeze()[\"__xarray_dataarray_variable__\"]\n",
    "    .isel(prediction_timedelta=slice(None, None, 4))\n",
    ")\n",
    "da_old.plot(col=\"prediction_timedelta\", col_wrap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a4f87-c297-4b28-bf70-3285b7b03993",
   "metadata": {},
   "outputs": [],
   "source": [
    "(da - da_old).plot(col=\"prediction_timedelta\", col_wrap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217797e-da44-4bf2-96d7-75f4db94ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(da - da_old).max().load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangu]",
   "language": "python",
   "name": "conda-env-pangu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
